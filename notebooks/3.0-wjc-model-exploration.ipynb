{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, RepeatedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from category_encoders import BinaryEncoder\n",
    "from ydata_profiling import ProfileReport\n",
    "import optuna\n",
    "\n",
    "# Modelos de Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from data.io import load_data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Adiciona o diret√≥rio raiz do projeto (titanic/) ao sys.path\n",
    "sys.path.append(str(Path().resolve().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados\n",
    "\n",
    "df_train = load_data('train.csv')\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Preprocessing = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), selector(dtype_include=\"number\")),\n",
    "        (\"cat\", OneHotEncoder(), selector(dtype_exclude=\"number\"))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=200),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Extra Trees': ExtraTreesClassifier(),\n",
    "    'MLP': MLPClassifier(max_iter=1000)\n",
    "}\n",
    "\n",
    "cv = RepeatedKFold(n_splits=3, n_repeats=10, random_state=None)\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "    (\"Organizing\", TransformData()),\n",
    "    (\"Preprocessing\", Preprocessing),\n",
    "    (\"Balancing\", SMOTE(sampling_strategy='auto', random_state=42)),\n",
    "    (\"Model\", model)\n",
    "    ])\n",
    "      \n",
    "    scores = cross_val_score(pipeline, features, target, cv=cv)\n",
    "    \n",
    "    results[name] = scores.mean()\n",
    "    \n",
    "    print(f\"{name} CV Accuracy: {results[name]:.4f}\")\n",
    "\n",
    "\n",
    "best_model_name = max(results, key=results.get)\n",
    "print(f\"\\nBest model based on CV: {best_model_name}\")\n",
    "\n",
    "# Train the best model on the full training set and evaluate it on the test set\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"Organizing\", TransformData()),\n",
    "    (\"Preprocessing\", Preprocessing),\n",
    "    (\"Model\", best_model)\n",
    "    ])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "test_accuracy = pipeline.score(X_test, y_test)\n",
    "print(f\"Test set Accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
